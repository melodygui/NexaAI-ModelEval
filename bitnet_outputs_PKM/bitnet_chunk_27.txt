
1. Introduction
Artificial intelligence (AI)  is an indispensable catalyst of societal transformation, shaping both our professional and personal landscapes. A key player in this transformation is generative AI, which has the potential to augment productivity and boost global economies. It is predicted that generative AI could add trillions of dollars in value to the global economy and significantly increase global GDP and productivity growth (McKinsey 2023, Goldman Sachs 2023). Generative AI’ s ability to generate a wide array of output forms—from text and code to images and videos—could potentially outpace human production capacity by 2030 (J. P. Morgan 2023). Particularly in marketing and sales, generative AI has the capacity to revolutionize the generation of creative content and reshape customer interactions, accounting for a substantial portion of the projected value of AI use cases (McKinsey 2023). Generative AI is already being used extensively in marketing for copywriting and creative generation. The partnership between technology titan Nvidia and the world’ s largest advertising agency, WPP, further exemplifies the transformative potential of generative AI in marketing (Ziady 2023). Given that marketing is dominant in shaping individuals’ perceptions, we believe that Generative AI can have a significant impact on shaping society. 1

2. Further, the impact of AI extends beyond commercial sectors, penetrating the realm of education. AI’ capacity to personalize learning experiences across all educational levels has been recognized (Rudra 2023). Generative AI can improve the learning process by providing tailored information, stimulating creativity, and enhancing digital skills, preparing learners for future workplace demands. In the context of digital publishing in education, generative AI’ s potential for significant cost reduction of content creation (e.g., text, image, audio, video) underscores its practical benefits (Alphonso 2023). While generative AI has numerous benefits in business and society, we must also remain aware and vigilant for potential drawbacks. Concerns arise about the technology’ potential risks, including issues related to intellectual property rights, accuracy of output, explainability of results, and potential propagation of harmful biases. Of significant concern is the potential bias embedded in generative AI models. Different from traditional AI models that are often used for classification or prediction, generative AI models are used to create new content based on patterns from the training data, making it difficult to measure the bias as there is no single “correct” output. Instead, one would need to evaluate a range of generated content for patterns that reflect bias. Moreover, new content generated by these models, such as visual content, can directly shape users’ perceptions, perpetuate harmful stereotypes, and even distort their beliefs, especially if the generated content is widely disseminated. For example, as educational tools increasingly harness generative AI, they inherently mold young minds and shape their worldview. Content tailored to student characteristics with potential bias may inadvertently propagate or solidify harmful stereotypes, shaping perceptions in ways that may be challenging to reverse. Since generative AI models are often trained on vast quantities of data collected from the internet, lack of control over the sources presents a formidable challenge in auditing and updating the training data to handle potential bias. As the training data may encompass a plethora of perspectives, cultures, and ideologies, it becomes increasingly challenging to anticipate, let alone correct, the myriad biases that could inadvertently find their way into the model. Furthermore, the situation is complicated by the proprietary nature of several major generative AI models. These models, often owned and maintained by private entities, are not publicly available for scrutiny. This lack of transparency further exacerbates the problem, as the broader academic community and society cannot easily assess or rectify biases in such closed systems. Given their increasing popularity and rapid adoption in many domains, generative AI models may inadvertently reinforce detrimental biases and stereotypes in our society, particularly in marketing and education. The current lack of well-defined regulations and policies in the domain of generative AI presents further risks, creating space for potentially harmful applications. This study investigates potential biases in three of the most popular text-to-image AI generators—Midjourney, Stable Diffusion, and DALL·E 2. These AI tools, ranging from commercial to open- source, can generate high-quality images from text prompts, a capability used by millions of users and deployed across various domains. Fig. 1 presents some examples of images generated by each model. While the prowess of these generative AI models is well-recognized across diverse domains, it is essential to examine how these models manifest biases and stereotypes within their outputs. 1

3. Analyses and Results
3.1. Gender Bias
In order to determine the gender distribution within our data, we utilized the Face++ API, one of the best face recognition APIs on the market (Eden AI 2023), to detect faces in each image and extract various features such as gender, smile, emotion, and age. Following this, we assessed the gender distribution within each image by calculating the percentage of women or men depicted

