
The following table lists the various open-source models that Lepton AI offers structured decoding for:

| Model Name | Open-Source | Description | Output Schema | API Compatibility | Notes |
| --- | --- | --- | --- | --- | --- |
| mixtral-8x7b | Mixtral AI | [function] | JSON | Guardrails AI | Prompt engineering |
| langchain-9x4d | LangChain AI | [function] | JSON | Guardrails AI | Prompt engineering |
| llama1-7b | LLaMA1 AI | [function] | JSON | OpenAI | Fine-tuning required |
| lepton-ai/llama2-70b | LLaMA2 AI | [function] | JSON | Lepton AI | Structured decoding capability |
| codellama-7b | Codellama AI | [function] | JSON | OpenAI | Fine-tuning required |
| codellama-13b | Codellama AI | [function] | JSON | OpenAI | Fine-tuning required |
| codellama-34b | Codellama AI | [function] | JSON | OpenAI | Fine-tuning required |
| mixtral-7x10b | Mixtral AI | [function] | JSON | Guardrails AI | Structured decoding capability |
| mixtral-8x7b | Mixtral AI | [function] | JSON | Guardrails AI | Structured decoding capability |
| llama2-7b | LLaMA2 AI | [function] | JSON | Lepton AI | Structured decoding capability |
| codellama-7b | Codellama AI | [function] | JSON | OpenAI | Fine-tuning required |
| codellama-13b | Codellama AI | [function] | JSON | OpenAI | Fine-tuning required |
| codellama-34b | Codellama AI | [function] | JSON | OpenAI | Fine-tuning required |

## Conclusion

In this tutorial, we have discussed how the next frontier for AI is to build agents: with LLMs as core controllers, leveraging LLMs’ strong capabilities in understanding unstructured text inputs, and generating structured data as outputs. We are proud to announce the general availability of the structured decoding capability for ALL the open-Source models hosted on Lepton AI. Simply provide the schema you want the LLM to produce, and all our model APIs will automatically produce outputs following the schema. In addition, you can host your own LLMs with structured decoding capability without having to finetune  — talk to us today at info@lepton.ai!
```

=== MODEL OUTPUT ENDS HERE ===

---

```html
<!DOCTYPE html> 
<html> 
  <head> 
    <title>Lepton AI Structured Decoding</title> 
  </head> 
  <body> 
    <h1>Lepton AI Structured Decoding</h1> 
    <p>Lepton AI offers structured decoding for various models:</p> 
    <table>
    <tr>
      <th>Model Name</th>
      <th>Description</th>
      <th>Output Schema</th>
      <th>API Compatibility</th>
      <th>Notes</th>
    </tr>
    <tr>
      <td>mixtral-8x7b</td>
      <td>[function]</td>
      <td>JSON</td>
      <td>Guardrails AI</td>
      <td>Prompt engineering</td>
    </tr>
    <tr>
      <td>langchain-9x4d</td>
      <td>[function]</td>
      <td>JSON</td>
      <td>Guardrails AI</td>
      <td>Prompt engineering</td>
    </tr>
    <tr>
      <td>llama1-7b</td>
      <td>[function]</td>
      <td>JSON</td>
      <td>OpenAI</td>
      <td>Fine-tuning required</td>
    </tr>
    <tr>
      <td>lepton-ai/llama2-70b</td>
      <td>[function]</td>
      <td>JSON</td>
      <td>Lepton AI</td>
      <td>Structured decoding capability</td>
      <td>Structured decoding capability</td>
    </tr>
    <tr>
      <td>codellama-7b</td>
      <td>[function]</td>
      <td>JSON</td>
      <td>Guardrails AI</td>
      <td>Prompt engineering</td>
    </tr>
    <tr>
      <td>codellama-13b</td>
      <td>[function]</td>
      <td>JSON</

